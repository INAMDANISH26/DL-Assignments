{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "name": "Ionosphere Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxEFRg_lYt9V"
      },
      "source": [
        "# Assignment: Ionosphere Data Problem\n",
        "\n",
        "### Dataset Description: \n",
        "\n",
        "This radar data was collected by a system in Goose Bay, Labrador. This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts. See the paper for more details. The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere. \"Bad\" returns are those that do not; their signals pass through the ionosphere.\n",
        "\n",
        "Received signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number. There were 17 pulse numbers for the Goose Bay system. Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.\n",
        "\n",
        "### Attribute Information:\n",
        "\n",
        "- All 34 are continuous\n",
        "- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above. This is a binary classification task.\n",
        "\n",
        " <br><br>\n",
        "\n",
        "<table border=\"1\"  cellpadding=\"6\">\n",
        "\t<tbody>\n",
        "        <tr>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">351</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Physical</p></td>\n",
        "        </tr>\n",
        "     </tbody>\n",
        "    </table>\n",
        "<table border=\"1\" cellpadding=\"6\">\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
        "            <td><p class=\"normal\">Integer,Real</p></td>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
        "            <td><p class=\"normal\">34</p></td>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
        "            <td><p class=\"normal\">N/A</p></td>\n",
        "        </tr>\n",
        "     </tbody>\n",
        "    </table>\n",
        "<table border=\"1\" cellpadding=\"6\">\t\n",
        "    <tbody>\n",
        "    <tr>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Classification</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
        "\t\t<td><p class=\"normal\">N/A</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">N/A</p></td>\n",
        "\t</tr>\n",
        "    </tbody>\n",
        "    </table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enYsn2pRYt9d"
      },
      "source": [
        "### WORKFLOW :\n",
        "- Load Data ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPNj5znTYt9e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "emDJcloZYt9f",
        "outputId": "91c69275-c69d-40a9-a8e7-86248e14f3f4"
      },
      "source": [
        "pd.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.1.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IiZxqz8KYt9g",
        "outputId": "1ef6bc2b-2c06-46a5-edb5-81d87c8affc7"
      },
      "source": [
        "np.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.19.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gmgyCH6Yt9h"
      },
      "source": [
        "# Load Data:\n",
        "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/ionosphere_data.csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3bym32NYt9h"
      },
      "source": [
        "Loading data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIN1Y4zGYt9i"
      },
      "source": [
        "# Load the dataset.\n",
        "df = pd.read_csv('./drive/MyDrive/ionosphere_data.csv', delimiter=',')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG0-JazeawbR",
        "outputId": "41c4cb52-f541-4a99-ad66-835332cbc6ed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftJeEJ5wYt9i",
        "outputId": "cc995138-1f55-4b48-e0bd-d498f9574417"
      },
      "source": [
        "# Find the shape of the dataset \n",
        "df.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(351, 35)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChFwJv4vYt9j"
      },
      "source": [
        "It's clear from the shape of the data that dataset is not a huge one. Only 351 records are available with 34 features/columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "yhWba_m9Yt9k",
        "outputId": "9cc27603-7a71-4e83-8f90-f91a56d17ce2"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99539</td>\n",
              "      <td>-0.05889</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>0.02306</td>\n",
              "      <td>0.83398</td>\n",
              "      <td>-0.37708</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.03760</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>-0.17755</td>\n",
              "      <td>0.59755</td>\n",
              "      <td>-0.44945</td>\n",
              "      <td>0.60536</td>\n",
              "      <td>-0.38223</td>\n",
              "      <td>0.84356</td>\n",
              "      <td>-0.38542</td>\n",
              "      <td>0.58212</td>\n",
              "      <td>-0.32192</td>\n",
              "      <td>0.56971</td>\n",
              "      <td>-0.29674</td>\n",
              "      <td>0.36946</td>\n",
              "      <td>-0.47357</td>\n",
              "      <td>0.56811</td>\n",
              "      <td>-0.51171</td>\n",
              "      <td>0.41078</td>\n",
              "      <td>-0.46168</td>\n",
              "      <td>0.21266</td>\n",
              "      <td>-0.34090</td>\n",
              "      <td>0.42267</td>\n",
              "      <td>-0.54487</td>\n",
              "      <td>0.18641</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.18829</td>\n",
              "      <td>0.93035</td>\n",
              "      <td>-0.36156</td>\n",
              "      <td>-0.10868</td>\n",
              "      <td>-0.93597</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.04549</td>\n",
              "      <td>0.50874</td>\n",
              "      <td>-0.67743</td>\n",
              "      <td>0.34432</td>\n",
              "      <td>-0.69707</td>\n",
              "      <td>-0.51685</td>\n",
              "      <td>-0.97515</td>\n",
              "      <td>0.05499</td>\n",
              "      <td>-0.62237</td>\n",
              "      <td>0.33109</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.13151</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>-0.18056</td>\n",
              "      <td>-0.35734</td>\n",
              "      <td>-0.20332</td>\n",
              "      <td>-0.26569</td>\n",
              "      <td>-0.20468</td>\n",
              "      <td>-0.18401</td>\n",
              "      <td>-0.19040</td>\n",
              "      <td>-0.11593</td>\n",
              "      <td>-0.16626</td>\n",
              "      <td>-0.06288</td>\n",
              "      <td>-0.13738</td>\n",
              "      <td>-0.02447</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.03365</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00485</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.88965</td>\n",
              "      <td>0.01198</td>\n",
              "      <td>0.73082</td>\n",
              "      <td>0.05346</td>\n",
              "      <td>0.85443</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54591</td>\n",
              "      <td>0.00299</td>\n",
              "      <td>0.83775</td>\n",
              "      <td>-0.13644</td>\n",
              "      <td>0.75535</td>\n",
              "      <td>-0.08540</td>\n",
              "      <td>0.70887</td>\n",
              "      <td>-0.27502</td>\n",
              "      <td>0.43385</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.57528</td>\n",
              "      <td>-0.40220</td>\n",
              "      <td>0.58984</td>\n",
              "      <td>-0.22145</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>-0.17365</td>\n",
              "      <td>0.60436</td>\n",
              "      <td>-0.24180</td>\n",
              "      <td>0.56045</td>\n",
              "      <td>-0.38238</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.45161</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.71216</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.14516</td>\n",
              "      <td>0.54094</td>\n",
              "      <td>-0.39330</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.54467</td>\n",
              "      <td>-0.69975</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.90695</td>\n",
              "      <td>0.51613</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.20099</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.32382</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02401</td>\n",
              "      <td>0.94140</td>\n",
              "      <td>0.06531</td>\n",
              "      <td>0.92106</td>\n",
              "      <td>-0.23255</td>\n",
              "      <td>0.77152</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>0.52798</td>\n",
              "      <td>-0.20275</td>\n",
              "      <td>0.56409</td>\n",
              "      <td>-0.00712</td>\n",
              "      <td>0.34395</td>\n",
              "      <td>-0.27457</td>\n",
              "      <td>0.52940</td>\n",
              "      <td>-0.21780</td>\n",
              "      <td>0.45107</td>\n",
              "      <td>-0.17813</td>\n",
              "      <td>0.05982</td>\n",
              "      <td>-0.35575</td>\n",
              "      <td>0.02309</td>\n",
              "      <td>-0.52879</td>\n",
              "      <td>0.03286</td>\n",
              "      <td>-0.65158</td>\n",
              "      <td>0.13290</td>\n",
              "      <td>-0.53206</td>\n",
              "      <td>0.02431</td>\n",
              "      <td>-0.62197</td>\n",
              "      <td>-0.05707</td>\n",
              "      <td>-0.59573</td>\n",
              "      <td>-0.04608</td>\n",
              "      <td>-0.65697</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature1  feature2  feature3  ...  feature33  feature34  label\n",
              "0         1         0   0.99539  ...    0.18641   -0.45300      g\n",
              "1         1         0   1.00000  ...   -0.13738   -0.02447      b\n",
              "2         1         0   1.00000  ...    0.56045   -0.38238      g\n",
              "3         1         0   1.00000  ...   -0.32382    1.00000      b\n",
              "4         1         0   1.00000  ...   -0.04608   -0.65697      g\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X3kVKLwYt9l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qTrHh1sjYt9l",
        "outputId": "a0a3c8d6-3e29-40be-b1c2-addabffe7bc6"
      },
      "source": [
        "df.describe().T"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>feature1</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.891738</td>\n",
              "      <td>0.311155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature2</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature3</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.641342</td>\n",
              "      <td>0.497708</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.472135</td>\n",
              "      <td>0.87111</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature4</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.044372</td>\n",
              "      <td>0.441435</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.064735</td>\n",
              "      <td>0.01631</td>\n",
              "      <td>0.194185</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature5</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.601068</td>\n",
              "      <td>0.519862</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.412660</td>\n",
              "      <td>0.80920</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature6</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.115889</td>\n",
              "      <td>0.460810</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.024795</td>\n",
              "      <td>0.02280</td>\n",
              "      <td>0.334655</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature7</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.550095</td>\n",
              "      <td>0.492654</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.211310</td>\n",
              "      <td>0.72873</td>\n",
              "      <td>0.969240</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature8</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.119360</td>\n",
              "      <td>0.520750</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.054840</td>\n",
              "      <td>0.01471</td>\n",
              "      <td>0.445675</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature9</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.511848</td>\n",
              "      <td>0.507066</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.087110</td>\n",
              "      <td>0.68421</td>\n",
              "      <td>0.953240</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature10</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.181345</td>\n",
              "      <td>0.483851</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.048075</td>\n",
              "      <td>0.01829</td>\n",
              "      <td>0.534195</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature11</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.476183</td>\n",
              "      <td>0.563496</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.021120</td>\n",
              "      <td>0.66798</td>\n",
              "      <td>0.957895</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature12</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.155040</td>\n",
              "      <td>0.494817</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.065265</td>\n",
              "      <td>0.02825</td>\n",
              "      <td>0.482375</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature13</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.400801</td>\n",
              "      <td>0.622186</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.64407</td>\n",
              "      <td>0.955505</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature14</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.093414</td>\n",
              "      <td>0.494873</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.073725</td>\n",
              "      <td>0.03027</td>\n",
              "      <td>0.374860</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature15</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.344159</td>\n",
              "      <td>0.652828</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.60194</td>\n",
              "      <td>0.919330</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature16</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.071132</td>\n",
              "      <td>0.458371</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.081705</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.308975</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature17</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.381949</td>\n",
              "      <td>0.618020</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.59091</td>\n",
              "      <td>0.935705</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature18</th>\n",
              "      <td>351.0</td>\n",
              "      <td>-0.003617</td>\n",
              "      <td>0.496762</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.225690</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.195285</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature19</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.359390</td>\n",
              "      <td>0.626267</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.57619</td>\n",
              "      <td>0.899265</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature20</th>\n",
              "      <td>351.0</td>\n",
              "      <td>-0.024025</td>\n",
              "      <td>0.519076</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.234670</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.134370</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature21</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.336695</td>\n",
              "      <td>0.609828</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.49909</td>\n",
              "      <td>0.894865</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature22</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.008296</td>\n",
              "      <td>0.518166</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.243870</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.188760</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature23</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.362475</td>\n",
              "      <td>0.603767</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.53176</td>\n",
              "      <td>0.911235</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature24</th>\n",
              "      <td>351.0</td>\n",
              "      <td>-0.057406</td>\n",
              "      <td>0.527456</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.366885</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.164630</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature25</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.396135</td>\n",
              "      <td>0.578451</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.55389</td>\n",
              "      <td>0.905240</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature26</th>\n",
              "      <td>351.0</td>\n",
              "      <td>-0.071187</td>\n",
              "      <td>0.508495</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.332390</td>\n",
              "      <td>-0.01505</td>\n",
              "      <td>0.156765</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature27</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.541641</td>\n",
              "      <td>0.516205</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.286435</td>\n",
              "      <td>0.70824</td>\n",
              "      <td>0.999945</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature28</th>\n",
              "      <td>351.0</td>\n",
              "      <td>-0.069538</td>\n",
              "      <td>0.550025</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.443165</td>\n",
              "      <td>-0.01769</td>\n",
              "      <td>0.153535</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature29</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.378445</td>\n",
              "      <td>0.575886</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.49664</td>\n",
              "      <td>0.883465</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature30</th>\n",
              "      <td>351.0</td>\n",
              "      <td>-0.027907</td>\n",
              "      <td>0.507974</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.236885</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.154075</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature31</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.352514</td>\n",
              "      <td>0.571483</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.44277</td>\n",
              "      <td>0.857620</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature32</th>\n",
              "      <td>351.0</td>\n",
              "      <td>-0.003794</td>\n",
              "      <td>0.513574</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.242595</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.200120</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature33</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.349364</td>\n",
              "      <td>0.522663</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.40956</td>\n",
              "      <td>0.813765</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature34</th>\n",
              "      <td>351.0</td>\n",
              "      <td>0.014480</td>\n",
              "      <td>0.468337</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.165350</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.171660</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           count      mean       std  min       25%      50%       75%  max\n",
              "feature1   351.0  0.891738  0.311155  0.0  1.000000  1.00000  1.000000  1.0\n",
              "feature2   351.0  0.000000  0.000000  0.0  0.000000  0.00000  0.000000  0.0\n",
              "feature3   351.0  0.641342  0.497708 -1.0  0.472135  0.87111  1.000000  1.0\n",
              "feature4   351.0  0.044372  0.441435 -1.0 -0.064735  0.01631  0.194185  1.0\n",
              "feature5   351.0  0.601068  0.519862 -1.0  0.412660  0.80920  1.000000  1.0\n",
              "feature6   351.0  0.115889  0.460810 -1.0 -0.024795  0.02280  0.334655  1.0\n",
              "feature7   351.0  0.550095  0.492654 -1.0  0.211310  0.72873  0.969240  1.0\n",
              "feature8   351.0  0.119360  0.520750 -1.0 -0.054840  0.01471  0.445675  1.0\n",
              "feature9   351.0  0.511848  0.507066 -1.0  0.087110  0.68421  0.953240  1.0\n",
              "feature10  351.0  0.181345  0.483851 -1.0 -0.048075  0.01829  0.534195  1.0\n",
              "feature11  351.0  0.476183  0.563496 -1.0  0.021120  0.66798  0.957895  1.0\n",
              "feature12  351.0  0.155040  0.494817 -1.0 -0.065265  0.02825  0.482375  1.0\n",
              "feature13  351.0  0.400801  0.622186 -1.0  0.000000  0.64407  0.955505  1.0\n",
              "feature14  351.0  0.093414  0.494873 -1.0 -0.073725  0.03027  0.374860  1.0\n",
              "feature15  351.0  0.344159  0.652828 -1.0  0.000000  0.60194  0.919330  1.0\n",
              "feature16  351.0  0.071132  0.458371 -1.0 -0.081705  0.00000  0.308975  1.0\n",
              "feature17  351.0  0.381949  0.618020 -1.0  0.000000  0.59091  0.935705  1.0\n",
              "feature18  351.0 -0.003617  0.496762 -1.0 -0.225690  0.00000  0.195285  1.0\n",
              "feature19  351.0  0.359390  0.626267 -1.0  0.000000  0.57619  0.899265  1.0\n",
              "feature20  351.0 -0.024025  0.519076 -1.0 -0.234670  0.00000  0.134370  1.0\n",
              "feature21  351.0  0.336695  0.609828 -1.0  0.000000  0.49909  0.894865  1.0\n",
              "feature22  351.0  0.008296  0.518166 -1.0 -0.243870  0.00000  0.188760  1.0\n",
              "feature23  351.0  0.362475  0.603767 -1.0  0.000000  0.53176  0.911235  1.0\n",
              "feature24  351.0 -0.057406  0.527456 -1.0 -0.366885  0.00000  0.164630  1.0\n",
              "feature25  351.0  0.396135  0.578451 -1.0  0.000000  0.55389  0.905240  1.0\n",
              "feature26  351.0 -0.071187  0.508495 -1.0 -0.332390 -0.01505  0.156765  1.0\n",
              "feature27  351.0  0.541641  0.516205 -1.0  0.286435  0.70824  0.999945  1.0\n",
              "feature28  351.0 -0.069538  0.550025 -1.0 -0.443165 -0.01769  0.153535  1.0\n",
              "feature29  351.0  0.378445  0.575886 -1.0  0.000000  0.49664  0.883465  1.0\n",
              "feature30  351.0 -0.027907  0.507974 -1.0 -0.236885  0.00000  0.154075  1.0\n",
              "feature31  351.0  0.352514  0.571483 -1.0  0.000000  0.44277  0.857620  1.0\n",
              "feature32  351.0 -0.003794  0.513574 -1.0 -0.242595  0.00000  0.200120  1.0\n",
              "feature33  351.0  0.349364  0.522663 -1.0  0.000000  0.40956  0.813765  1.0\n",
              "feature34  351.0  0.014480  0.468337 -1.0 -0.165350  0.00000  0.171660  1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okhIr6tlYt9m",
        "outputId": "f6e669c4-de2d-445d-c487-e4a421d799a8"
      },
      "source": [
        "for feature in df:\n",
        "    print(feature)\n",
        "    print(len(df[feature].unique()))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature1\n",
            "2\n",
            "feature2\n",
            "1\n",
            "feature3\n",
            "219\n",
            "feature4\n",
            "269\n",
            "feature5\n",
            "204\n",
            "feature6\n",
            "259\n",
            "feature7\n",
            "231\n",
            "feature8\n",
            "260\n",
            "feature9\n",
            "244\n",
            "feature10\n",
            "267\n",
            "feature11\n",
            "246\n",
            "feature12\n",
            "269\n",
            "feature13\n",
            "238\n",
            "feature14\n",
            "266\n",
            "feature15\n",
            "234\n",
            "feature16\n",
            "270\n",
            "feature17\n",
            "254\n",
            "feature18\n",
            "280\n",
            "feature19\n",
            "254\n",
            "feature20\n",
            "266\n",
            "feature21\n",
            "248\n",
            "feature22\n",
            "265\n",
            "feature23\n",
            "248\n",
            "feature24\n",
            "264\n",
            "feature25\n",
            "256\n",
            "feature26\n",
            "273\n",
            "feature27\n",
            "256\n",
            "feature28\n",
            "281\n",
            "feature29\n",
            "244\n",
            "feature30\n",
            "266\n",
            "feature31\n",
            "243\n",
            "feature32\n",
            "263\n",
            "feature33\n",
            "245\n",
            "feature34\n",
            "263\n",
            "label\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYvbNxldYt9m",
        "outputId": "d36293c3-ff2f-4873-c40a-94deaf668fc7"
      },
      "source": [
        "df['feature2'].unique()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dxCTBauYt9n"
      },
      "source": [
        "df.drop(df.columns[1], inplace=True, axis=1)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "gC099ij9Yt9n",
        "outputId": "218ab484-cb19-4d78-bb15-03ddc442782d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.99539</td>\n",
              "      <td>-0.05889</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>0.02306</td>\n",
              "      <td>0.83398</td>\n",
              "      <td>-0.37708</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.03760</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>-0.17755</td>\n",
              "      <td>0.59755</td>\n",
              "      <td>-0.44945</td>\n",
              "      <td>0.60536</td>\n",
              "      <td>-0.38223</td>\n",
              "      <td>0.84356</td>\n",
              "      <td>-0.38542</td>\n",
              "      <td>0.58212</td>\n",
              "      <td>-0.32192</td>\n",
              "      <td>0.56971</td>\n",
              "      <td>-0.29674</td>\n",
              "      <td>0.36946</td>\n",
              "      <td>-0.47357</td>\n",
              "      <td>0.56811</td>\n",
              "      <td>-0.51171</td>\n",
              "      <td>0.41078</td>\n",
              "      <td>-0.46168</td>\n",
              "      <td>0.21266</td>\n",
              "      <td>-0.34090</td>\n",
              "      <td>0.42267</td>\n",
              "      <td>-0.54487</td>\n",
              "      <td>0.18641</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.18829</td>\n",
              "      <td>0.93035</td>\n",
              "      <td>-0.36156</td>\n",
              "      <td>-0.10868</td>\n",
              "      <td>-0.93597</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.04549</td>\n",
              "      <td>0.50874</td>\n",
              "      <td>-0.67743</td>\n",
              "      <td>0.34432</td>\n",
              "      <td>-0.69707</td>\n",
              "      <td>-0.51685</td>\n",
              "      <td>-0.97515</td>\n",
              "      <td>0.05499</td>\n",
              "      <td>-0.62237</td>\n",
              "      <td>0.33109</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.13151</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>-0.18056</td>\n",
              "      <td>-0.35734</td>\n",
              "      <td>-0.20332</td>\n",
              "      <td>-0.26569</td>\n",
              "      <td>-0.20468</td>\n",
              "      <td>-0.18401</td>\n",
              "      <td>-0.19040</td>\n",
              "      <td>-0.11593</td>\n",
              "      <td>-0.16626</td>\n",
              "      <td>-0.06288</td>\n",
              "      <td>-0.13738</td>\n",
              "      <td>-0.02447</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.03365</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00485</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.88965</td>\n",
              "      <td>0.01198</td>\n",
              "      <td>0.73082</td>\n",
              "      <td>0.05346</td>\n",
              "      <td>0.85443</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54591</td>\n",
              "      <td>0.00299</td>\n",
              "      <td>0.83775</td>\n",
              "      <td>-0.13644</td>\n",
              "      <td>0.75535</td>\n",
              "      <td>-0.08540</td>\n",
              "      <td>0.70887</td>\n",
              "      <td>-0.27502</td>\n",
              "      <td>0.43385</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.57528</td>\n",
              "      <td>-0.40220</td>\n",
              "      <td>0.58984</td>\n",
              "      <td>-0.22145</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>-0.17365</td>\n",
              "      <td>0.60436</td>\n",
              "      <td>-0.24180</td>\n",
              "      <td>0.56045</td>\n",
              "      <td>-0.38238</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.45161</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.71216</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.14516</td>\n",
              "      <td>0.54094</td>\n",
              "      <td>-0.39330</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.54467</td>\n",
              "      <td>-0.69975</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.90695</td>\n",
              "      <td>0.51613</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.20099</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.32382</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02401</td>\n",
              "      <td>0.94140</td>\n",
              "      <td>0.06531</td>\n",
              "      <td>0.92106</td>\n",
              "      <td>-0.23255</td>\n",
              "      <td>0.77152</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>0.52798</td>\n",
              "      <td>-0.20275</td>\n",
              "      <td>0.56409</td>\n",
              "      <td>-0.00712</td>\n",
              "      <td>0.34395</td>\n",
              "      <td>-0.27457</td>\n",
              "      <td>0.52940</td>\n",
              "      <td>-0.21780</td>\n",
              "      <td>0.45107</td>\n",
              "      <td>-0.17813</td>\n",
              "      <td>0.05982</td>\n",
              "      <td>-0.35575</td>\n",
              "      <td>0.02309</td>\n",
              "      <td>-0.52879</td>\n",
              "      <td>0.03286</td>\n",
              "      <td>-0.65158</td>\n",
              "      <td>0.13290</td>\n",
              "      <td>-0.53206</td>\n",
              "      <td>0.02431</td>\n",
              "      <td>-0.62197</td>\n",
              "      <td>-0.05707</td>\n",
              "      <td>-0.59573</td>\n",
              "      <td>-0.04608</td>\n",
              "      <td>-0.65697</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   feature1  feature3  feature4  ...  feature33  feature34  label\n",
              "0         1   0.99539  -0.05889  ...    0.18641   -0.45300      g\n",
              "1         1   1.00000  -0.18829  ...   -0.13738   -0.02447      b\n",
              "2         1   1.00000  -0.03365  ...    0.56045   -0.38238      g\n",
              "3         1   1.00000  -0.45161  ...   -0.32382    1.00000      b\n",
              "4         1   1.00000  -0.02401  ...   -0.04608   -0.65697      g\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3J_PwSmYt9p",
        "outputId": "da9d12af-ee9c-439f-9d91-96fa9205d379"
      },
      "source": [
        "df.ndim"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQK9tDtbYt9p",
        "outputId": "fc9706dd-321b-410a-9a93-5a468cb83a12"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 351 entries, 0 to 350\n",
            "Data columns (total 34 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   feature1   351 non-null    int64  \n",
            " 1   feature3   351 non-null    float64\n",
            " 2   feature4   351 non-null    float64\n",
            " 3   feature5   351 non-null    float64\n",
            " 4   feature6   351 non-null    float64\n",
            " 5   feature7   351 non-null    float64\n",
            " 6   feature8   351 non-null    float64\n",
            " 7   feature9   351 non-null    float64\n",
            " 8   feature10  351 non-null    float64\n",
            " 9   feature11  351 non-null    float64\n",
            " 10  feature12  351 non-null    float64\n",
            " 11  feature13  351 non-null    float64\n",
            " 12  feature14  351 non-null    float64\n",
            " 13  feature15  351 non-null    float64\n",
            " 14  feature16  351 non-null    float64\n",
            " 15  feature17  351 non-null    float64\n",
            " 16  feature18  351 non-null    float64\n",
            " 17  feature19  351 non-null    float64\n",
            " 18  feature20  351 non-null    float64\n",
            " 19  feature21  351 non-null    float64\n",
            " 20  feature22  351 non-null    float64\n",
            " 21  feature23  351 non-null    float64\n",
            " 22  feature24  351 non-null    float64\n",
            " 23  feature25  351 non-null    float64\n",
            " 24  feature26  351 non-null    float64\n",
            " 25  feature27  351 non-null    float64\n",
            " 26  feature28  351 non-null    float64\n",
            " 27  feature29  351 non-null    float64\n",
            " 28  feature30  351 non-null    float64\n",
            " 29  feature31  351 non-null    float64\n",
            " 30  feature32  351 non-null    float64\n",
            " 31  feature33  351 non-null    float64\n",
            " 32  feature34  351 non-null    float64\n",
            " 33  label      351 non-null    object \n",
            "dtypes: float64(32), int64(1), object(1)\n",
            "memory usage: 93.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "Q68SsK4bYt9q",
        "outputId": "55ab7d47-134a-4f4b-e1ce-a4c59cd77cf5"
      },
      "source": [
        "# Check summary statistics\n",
        "df.describe()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "      <td>351.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.891738</td>\n",
              "      <td>0.641342</td>\n",
              "      <td>0.044372</td>\n",
              "      <td>0.601068</td>\n",
              "      <td>0.115889</td>\n",
              "      <td>0.550095</td>\n",
              "      <td>0.119360</td>\n",
              "      <td>0.511848</td>\n",
              "      <td>0.181345</td>\n",
              "      <td>0.476183</td>\n",
              "      <td>0.155040</td>\n",
              "      <td>0.400801</td>\n",
              "      <td>0.093414</td>\n",
              "      <td>0.344159</td>\n",
              "      <td>0.071132</td>\n",
              "      <td>0.381949</td>\n",
              "      <td>-0.003617</td>\n",
              "      <td>0.359390</td>\n",
              "      <td>-0.024025</td>\n",
              "      <td>0.336695</td>\n",
              "      <td>0.008296</td>\n",
              "      <td>0.362475</td>\n",
              "      <td>-0.057406</td>\n",
              "      <td>0.396135</td>\n",
              "      <td>-0.071187</td>\n",
              "      <td>0.541641</td>\n",
              "      <td>-0.069538</td>\n",
              "      <td>0.378445</td>\n",
              "      <td>-0.027907</td>\n",
              "      <td>0.352514</td>\n",
              "      <td>-0.003794</td>\n",
              "      <td>0.349364</td>\n",
              "      <td>0.014480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.311155</td>\n",
              "      <td>0.497708</td>\n",
              "      <td>0.441435</td>\n",
              "      <td>0.519862</td>\n",
              "      <td>0.460810</td>\n",
              "      <td>0.492654</td>\n",
              "      <td>0.520750</td>\n",
              "      <td>0.507066</td>\n",
              "      <td>0.483851</td>\n",
              "      <td>0.563496</td>\n",
              "      <td>0.494817</td>\n",
              "      <td>0.622186</td>\n",
              "      <td>0.494873</td>\n",
              "      <td>0.652828</td>\n",
              "      <td>0.458371</td>\n",
              "      <td>0.618020</td>\n",
              "      <td>0.496762</td>\n",
              "      <td>0.626267</td>\n",
              "      <td>0.519076</td>\n",
              "      <td>0.609828</td>\n",
              "      <td>0.518166</td>\n",
              "      <td>0.603767</td>\n",
              "      <td>0.527456</td>\n",
              "      <td>0.578451</td>\n",
              "      <td>0.508495</td>\n",
              "      <td>0.516205</td>\n",
              "      <td>0.550025</td>\n",
              "      <td>0.575886</td>\n",
              "      <td>0.507974</td>\n",
              "      <td>0.571483</td>\n",
              "      <td>0.513574</td>\n",
              "      <td>0.522663</td>\n",
              "      <td>0.468337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.472135</td>\n",
              "      <td>-0.064735</td>\n",
              "      <td>0.412660</td>\n",
              "      <td>-0.024795</td>\n",
              "      <td>0.211310</td>\n",
              "      <td>-0.054840</td>\n",
              "      <td>0.087110</td>\n",
              "      <td>-0.048075</td>\n",
              "      <td>0.021120</td>\n",
              "      <td>-0.065265</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.073725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.081705</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.225690</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.234670</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.243870</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.366885</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.332390</td>\n",
              "      <td>0.286435</td>\n",
              "      <td>-0.443165</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.236885</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.242595</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.165350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.871110</td>\n",
              "      <td>0.016310</td>\n",
              "      <td>0.809200</td>\n",
              "      <td>0.022800</td>\n",
              "      <td>0.728730</td>\n",
              "      <td>0.014710</td>\n",
              "      <td>0.684210</td>\n",
              "      <td>0.018290</td>\n",
              "      <td>0.667980</td>\n",
              "      <td>0.028250</td>\n",
              "      <td>0.644070</td>\n",
              "      <td>0.030270</td>\n",
              "      <td>0.601940</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.590910</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.576190</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.499090</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.531760</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.553890</td>\n",
              "      <td>-0.015050</td>\n",
              "      <td>0.708240</td>\n",
              "      <td>-0.017690</td>\n",
              "      <td>0.496640</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.442770</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.409560</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.194185</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.334655</td>\n",
              "      <td>0.969240</td>\n",
              "      <td>0.445675</td>\n",
              "      <td>0.953240</td>\n",
              "      <td>0.534195</td>\n",
              "      <td>0.957895</td>\n",
              "      <td>0.482375</td>\n",
              "      <td>0.955505</td>\n",
              "      <td>0.374860</td>\n",
              "      <td>0.919330</td>\n",
              "      <td>0.308975</td>\n",
              "      <td>0.935705</td>\n",
              "      <td>0.195285</td>\n",
              "      <td>0.899265</td>\n",
              "      <td>0.134370</td>\n",
              "      <td>0.894865</td>\n",
              "      <td>0.188760</td>\n",
              "      <td>0.911235</td>\n",
              "      <td>0.164630</td>\n",
              "      <td>0.905240</td>\n",
              "      <td>0.156765</td>\n",
              "      <td>0.999945</td>\n",
              "      <td>0.153535</td>\n",
              "      <td>0.883465</td>\n",
              "      <td>0.154075</td>\n",
              "      <td>0.857620</td>\n",
              "      <td>0.200120</td>\n",
              "      <td>0.813765</td>\n",
              "      <td>0.171660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         feature1    feature3    feature4  ...   feature32   feature33   feature34\n",
              "count  351.000000  351.000000  351.000000  ...  351.000000  351.000000  351.000000\n",
              "mean     0.891738    0.641342    0.044372  ...   -0.003794    0.349364    0.014480\n",
              "std      0.311155    0.497708    0.441435  ...    0.513574    0.522663    0.468337\n",
              "min      0.000000   -1.000000   -1.000000  ...   -1.000000   -1.000000   -1.000000\n",
              "25%      1.000000    0.472135   -0.064735  ...   -0.242595    0.000000   -0.165350\n",
              "50%      1.000000    0.871110    0.016310  ...    0.000000    0.409560    0.000000\n",
              "75%      1.000000    1.000000    0.194185  ...    0.200120    0.813765    0.171660\n",
              "max      1.000000    1.000000    1.000000  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[8 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4zaEpWvYt9r"
      },
      "source": [
        "- Check Missing Values ( If Exist ; Fill each record with mean of its feature ) or any usless column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zkj_dEAYt9s",
        "outputId": "0aeed53f-091e-4e36-b292-8309b94433fc"
      },
      "source": [
        "# Find missing values\n",
        "df.isnull().sum()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature1     0\n",
              "feature3     0\n",
              "feature4     0\n",
              "feature5     0\n",
              "feature6     0\n",
              "feature7     0\n",
              "feature8     0\n",
              "feature9     0\n",
              "feature10    0\n",
              "feature11    0\n",
              "feature12    0\n",
              "feature13    0\n",
              "feature14    0\n",
              "feature15    0\n",
              "feature16    0\n",
              "feature17    0\n",
              "feature18    0\n",
              "feature19    0\n",
              "feature20    0\n",
              "feature21    0\n",
              "feature22    0\n",
              "feature23    0\n",
              "feature24    0\n",
              "feature25    0\n",
              "feature26    0\n",
              "feature27    0\n",
              "feature28    0\n",
              "feature29    0\n",
              "feature30    0\n",
              "feature31    0\n",
              "feature32    0\n",
              "feature33    0\n",
              "feature34    0\n",
              "label        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu8rbIcRYt9s"
      },
      "source": [
        "df['label'] = [1 if lbl == 'g' else 0 for lbl in df['label']]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oaKpKWoYt9t"
      },
      "source": [
        "train_data = df.sample(frac= 0.6, random_state=125)\n",
        "test_data = df.drop(train_data.index)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9x5DG1bYt9t"
      },
      "source": [
        "train_label = train_data.iloc[:,-1]\n",
        "train_data = train_data.iloc[:,0:-1]\n",
        "test_label = test_data.iloc[:,-1]\n",
        "test_data = test_data.iloc[:,0:-1]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "ChpyzP8DYt9u",
        "outputId": "b48abe28-3774-4eca-d2b6-5aee8e7ddf57"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>feature13</th>\n",
              "      <th>feature14</th>\n",
              "      <th>feature15</th>\n",
              "      <th>feature16</th>\n",
              "      <th>feature17</th>\n",
              "      <th>feature18</th>\n",
              "      <th>feature19</th>\n",
              "      <th>feature20</th>\n",
              "      <th>feature21</th>\n",
              "      <th>feature22</th>\n",
              "      <th>feature23</th>\n",
              "      <th>feature24</th>\n",
              "      <th>feature25</th>\n",
              "      <th>feature26</th>\n",
              "      <th>feature27</th>\n",
              "      <th>feature28</th>\n",
              "      <th>feature29</th>\n",
              "      <th>feature30</th>\n",
              "      <th>feature31</th>\n",
              "      <th>feature32</th>\n",
              "      <th>feature33</th>\n",
              "      <th>feature34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>1</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.08013</td>\n",
              "      <td>0.96775</td>\n",
              "      <td>-0.00482</td>\n",
              "      <td>0.96683</td>\n",
              "      <td>-0.00722</td>\n",
              "      <td>0.87980</td>\n",
              "      <td>-0.03923</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.01419</td>\n",
              "      <td>0.96186</td>\n",
              "      <td>-0.01436</td>\n",
              "      <td>0.95947</td>\n",
              "      <td>-0.01671</td>\n",
              "      <td>0.98497</td>\n",
              "      <td>0.01002</td>\n",
              "      <td>0.91152</td>\n",
              "      <td>-0.08848</td>\n",
              "      <td>0.95016</td>\n",
              "      <td>-0.02364</td>\n",
              "      <td>0.94636</td>\n",
              "      <td>-0.02591</td>\n",
              "      <td>0.98164</td>\n",
              "      <td>0.02003</td>\n",
              "      <td>0.93772</td>\n",
              "      <td>-0.03034</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.05843</td>\n",
              "      <td>0.92774</td>\n",
              "      <td>-0.03464</td>\n",
              "      <td>0.92226</td>\n",
              "      <td>-0.03673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>1</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.14754</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.04918</td>\n",
              "      <td>0.57377</td>\n",
              "      <td>-0.01639</td>\n",
              "      <td>0.65574</td>\n",
              "      <td>0.01639</td>\n",
              "      <td>0.85246</td>\n",
              "      <td>-0.03279</td>\n",
              "      <td>0.72131</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.68852</td>\n",
              "      <td>-0.16393</td>\n",
              "      <td>0.19672</td>\n",
              "      <td>-0.14754</td>\n",
              "      <td>0.65558</td>\n",
              "      <td>-0.17176</td>\n",
              "      <td>0.67213</td>\n",
              "      <td>0.03279</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.29508</td>\n",
              "      <td>0.31148</td>\n",
              "      <td>-0.34426</td>\n",
              "      <td>0.52385</td>\n",
              "      <td>-0.20325</td>\n",
              "      <td>0.32787</td>\n",
              "      <td>-0.03279</td>\n",
              "      <td>0.27869</td>\n",
              "      <td>-0.44262</td>\n",
              "      <td>0.49180</td>\n",
              "      <td>-0.06557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>1</td>\n",
              "      <td>0.89706</td>\n",
              "      <td>0.38235</td>\n",
              "      <td>0.91176</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>0.74265</td>\n",
              "      <td>0.67647</td>\n",
              "      <td>0.45588</td>\n",
              "      <td>0.77941</td>\n",
              "      <td>0.19118</td>\n",
              "      <td>0.88971</td>\n",
              "      <td>-0.02206</td>\n",
              "      <td>0.86029</td>\n",
              "      <td>-0.20588</td>\n",
              "      <td>0.82353</td>\n",
              "      <td>-0.37500</td>\n",
              "      <td>0.67647</td>\n",
              "      <td>-0.50000</td>\n",
              "      <td>0.47794</td>\n",
              "      <td>-0.73529</td>\n",
              "      <td>0.38235</td>\n",
              "      <td>-0.86029</td>\n",
              "      <td>0.08824</td>\n",
              "      <td>-0.74265</td>\n",
              "      <td>-0.12500</td>\n",
              "      <td>-0.67925</td>\n",
              "      <td>-0.24131</td>\n",
              "      <td>-0.55147</td>\n",
              "      <td>-0.42647</td>\n",
              "      <td>-0.44118</td>\n",
              "      <td>-0.50735</td>\n",
              "      <td>-0.28676</td>\n",
              "      <td>-0.56618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>1</td>\n",
              "      <td>0.84557</td>\n",
              "      <td>-0.08580</td>\n",
              "      <td>-0.31745</td>\n",
              "      <td>-0.80553</td>\n",
              "      <td>-0.08961</td>\n",
              "      <td>-0.56435</td>\n",
              "      <td>0.80648</td>\n",
              "      <td>0.04576</td>\n",
              "      <td>0.89514</td>\n",
              "      <td>-0.00763</td>\n",
              "      <td>-0.18494</td>\n",
              "      <td>0.63966</td>\n",
              "      <td>-0.20019</td>\n",
              "      <td>-0.68065</td>\n",
              "      <td>0.85701</td>\n",
              "      <td>-0.11344</td>\n",
              "      <td>0.77979</td>\n",
              "      <td>-0.15729</td>\n",
              "      <td>-0.06959</td>\n",
              "      <td>0.50810</td>\n",
              "      <td>-0.34128</td>\n",
              "      <td>0.80934</td>\n",
              "      <td>0.78932</td>\n",
              "      <td>-0.03718</td>\n",
              "      <td>0.70882</td>\n",
              "      <td>-0.25288</td>\n",
              "      <td>0.77884</td>\n",
              "      <td>-0.14109</td>\n",
              "      <td>-0.21354</td>\n",
              "      <td>-0.78170</td>\n",
              "      <td>-0.18494</td>\n",
              "      <td>-0.59867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>1</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.77941</td>\n",
              "      <td>-0.99265</td>\n",
              "      <td>0.80882</td>\n",
              "      <td>0.55147</td>\n",
              "      <td>-0.41912</td>\n",
              "      <td>-0.94853</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.72059</td>\n",
              "      <td>-0.77206</td>\n",
              "      <td>0.73529</td>\n",
              "      <td>-0.60294</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.18382</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     feature1  feature3  feature4  ...  feature32  feature33  feature34\n",
              "270         1   1.00000   0.08013  ...   -0.03464    0.92226   -0.03673\n",
              "116         1   1.00000  -0.14754  ...   -0.44262    0.49180   -0.06557\n",
              "135         1   0.89706   0.38235  ...   -0.50735   -0.28676   -0.56618\n",
              "91          1   0.84557  -0.08580  ...   -0.78170   -0.18494   -0.59867\n",
              "100         1   1.00000  -1.00000  ...   -1.00000    0.00000    0.00000\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcGGY1NbYt9u",
        "outputId": "84c92f34-b0eb-461a-c070-35c8152d41f8"
      },
      "source": [
        "train_label"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "270    1\n",
              "116    0\n",
              "135    1\n",
              "91     0\n",
              "100    0\n",
              "      ..\n",
              "213    1\n",
              "161    1\n",
              "141    1\n",
              "59     0\n",
              "113    1\n",
              "Name: label, Length: 211, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4bqQu5XYt9w"
      },
      "source": [
        "- Encode labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqH-B_7aYt9x"
      },
      "source": [
        "- Shuffle the data if needed.\n",
        "- Split into 60 and 40 ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxmTjUOMYt9x"
      },
      "source": [
        "# Now sample the dataframe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYBCJ5i-Yt9y",
        "outputId": "28267e8b-c80c-4b9a-8ffa-f7a520079909"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(211, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm_AWM6sYt9y",
        "outputId": "6a649d3e-e6d2-47bd-ebf1-fc5e05e0c4d1"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140, 33)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecvMzcIUYt9z",
        "outputId": "659cc9ea-f39e-4a63-a209-ba781daef29c"
      },
      "source": [
        "train_label.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(211,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpOs-x_gYt9z",
        "outputId": "c032116b-6f8c-460d-9616-2d73a44d6c60"
      },
      "source": [
        "test_label.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QepCcjxDYt90",
        "outputId": "24c30a70-a67e-45db-82da-263c20ca4084"
      },
      "source": [
        "train_label.sum()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwuGzMZ8Yt91",
        "outputId": "d0d05578-0bfa-482d-97b0-a59a4e381b7f"
      },
      "source": [
        "len(train_label)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0929x0GYt91"
      },
      "source": [
        "# train_label.sum()/len(train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kle76WtzYt92"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3XyITwAYt92"
      },
      "source": [
        "train_data = train_data.to_numpy()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL8xPc6vYt92"
      },
      "source": [
        "train_label = train_label.to_numpy().astype('float32')"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbwMmSRbYt93"
      },
      "source": [
        "test_data = test_data.to_numpy()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1GJ0__hYt93"
      },
      "source": [
        "test_label = test_label.to_numpy().astype('float32')"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVmsnez8Yt93"
      },
      "source": [
        "#train_set = np.array(train_set.as_matrix())\n",
        "#train_label = np.array(pd.DataFrame(train_label).as_matrix())"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2glgzlqdYt94",
        "outputId": "b9dc1cde-0443-45d7-ad53-e7db14466c9e"
      },
      "source": [
        "print(type(train_data))\n",
        "print(type(train_label))\n",
        "print(type(test_data))\n",
        "print(type(test_label))\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvQQvmkzYt95",
        "outputId": "f7ec4355-0838-4e62-94bf-1d21b38c1947"
      },
      "source": [
        "print(train_data.dtype)\n",
        "print(train_label.dtype)\n",
        "print(test_label.dtype)\n",
        "print(test_data.dtype)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float64\n",
            "float32\n",
            "float32\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h74Bg6v0Yt95"
      },
      "source": [
        "### Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vUI-qHYYt96"
      },
      "source": [
        "- Model : 1 hidden layers including 16 unit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8Y0NYGyYt96"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Define model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(train_data.shape[1],)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1,  activation='sigmoid'))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjoiDgR1Yt96",
        "outputId": "c65635a7-e983-4dde-bf2d-eb54b4d9a962"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 128)               4352      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 12,673\n",
            "Trainable params: 12,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaR3RvU9Yt97"
      },
      "source": [
        "- Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In4buoIGYt97"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model.compile(optimizer = 'RMSprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHRcQ7ECYt98"
      },
      "source": [
        "- Train the Model with Epochs (100)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhJyOPhdYt98",
        "outputId": "cee0d914-a4eb-4607-812e-19d80dc9174d"
      },
      "source": [
        "history = model.fit(train_data, train_label, validation_split=0.25, epochs= 100, batch_size = 32)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 1s 43ms/step - loss: 0.7736 - accuracy: 0.4967 - val_loss: 0.5458 - val_accuracy: 0.8302\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5583 - accuracy: 0.7704 - val_loss: 0.4732 - val_accuracy: 0.8868\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4666 - accuracy: 0.8416 - val_loss: 0.4244 - val_accuracy: 0.8868\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4632 - accuracy: 0.8461 - val_loss: 0.3828 - val_accuracy: 0.9057\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3981 - accuracy: 0.9181 - val_loss: 0.3511 - val_accuracy: 0.9057\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3572 - accuracy: 0.9388 - val_loss: 0.3245 - val_accuracy: 0.9434\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3646 - accuracy: 0.9059 - val_loss: 0.3002 - val_accuracy: 0.9623\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3219 - accuracy: 0.9261 - val_loss: 0.2759 - val_accuracy: 0.9623\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3142 - accuracy: 0.9072 - val_loss: 0.2539 - val_accuracy: 0.9623\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2808 - accuracy: 0.9348 - val_loss: 0.2400 - val_accuracy: 0.9623\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2636 - accuracy: 0.9433 - val_loss: 0.2233 - val_accuracy: 0.9623\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2474 - accuracy: 0.9321 - val_loss: 0.2100 - val_accuracy: 0.9623\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2095 - accuracy: 0.9416 - val_loss: 0.2001 - val_accuracy: 0.9623\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1937 - accuracy: 0.9631 - val_loss: 0.1901 - val_accuracy: 0.9623\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1872 - accuracy: 0.9649 - val_loss: 0.1842 - val_accuracy: 0.9623\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1778 - accuracy: 0.9544 - val_loss: 0.1881 - val_accuracy: 0.9623\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1567 - accuracy: 0.9583 - val_loss: 0.1776 - val_accuracy: 0.9623\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1838 - accuracy: 0.9695 - val_loss: 0.1724 - val_accuracy: 0.9623\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1793 - accuracy: 0.9441 - val_loss: 0.1761 - val_accuracy: 0.9623\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1719 - accuracy: 0.9689 - val_loss: 0.1685 - val_accuracy: 0.9623\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1464 - accuracy: 0.9730 - val_loss: 0.1677 - val_accuracy: 0.9623\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1672 - accuracy: 0.9466 - val_loss: 0.1590 - val_accuracy: 0.9623\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1120 - accuracy: 0.9589 - val_loss: 0.1601 - val_accuracy: 0.9623\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1521 - accuracy: 0.9457 - val_loss: 0.1645 - val_accuracy: 0.9623\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1375 - accuracy: 0.9496 - val_loss: 0.1596 - val_accuracy: 0.9623\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1639 - accuracy: 0.9483 - val_loss: 0.1560 - val_accuracy: 0.9623\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1142 - accuracy: 0.9759 - val_loss: 0.1560 - val_accuracy: 0.9623\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1071 - accuracy: 0.9692 - val_loss: 0.1588 - val_accuracy: 0.9623\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1108 - accuracy: 0.9575 - val_loss: 0.1523 - val_accuracy: 0.9623\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1110 - accuracy: 0.9531 - val_loss: 0.1497 - val_accuracy: 0.9623\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1170 - accuracy: 0.9587 - val_loss: 0.1496 - val_accuracy: 0.9623\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1188 - accuracy: 0.9434 - val_loss: 0.1498 - val_accuracy: 0.9623\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1002 - accuracy: 0.9824 - val_loss: 0.1581 - val_accuracy: 0.9623\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1055 - accuracy: 0.9664 - val_loss: 0.1616 - val_accuracy: 0.9623\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1009 - accuracy: 0.9720 - val_loss: 0.1652 - val_accuracy: 0.9623\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0759 - accuracy: 0.9764 - val_loss: 0.1508 - val_accuracy: 0.9623\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0743 - accuracy: 0.9897 - val_loss: 0.1575 - val_accuracy: 0.9623\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0646 - accuracy: 0.9901 - val_loss: 0.1652 - val_accuracy: 0.9623\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0616 - accuracy: 0.9945 - val_loss: 0.1496 - val_accuracy: 0.9623\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0662 - accuracy: 0.9820 - val_loss: 0.1591 - val_accuracy: 0.9623\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0725 - accuracy: 0.9715 - val_loss: 0.1585 - val_accuracy: 0.9623\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0497 - accuracy: 0.9901 - val_loss: 0.1471 - val_accuracy: 0.9623\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0612 - accuracy: 0.9793 - val_loss: 0.1534 - val_accuracy: 0.9623\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0904 - accuracy: 0.9500 - val_loss: 0.1482 - val_accuracy: 0.9623\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0592 - accuracy: 0.9712 - val_loss: 0.1397 - val_accuracy: 0.9623\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0613 - accuracy: 0.9785 - val_loss: 0.1395 - val_accuracy: 0.9623\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0357 - accuracy: 0.9927 - val_loss: 0.1365 - val_accuracy: 0.9623\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0594 - accuracy: 0.9859 - val_loss: 0.1466 - val_accuracy: 0.9623\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0351 - accuracy: 0.9966 - val_loss: 0.1439 - val_accuracy: 0.9623\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0707 - accuracy: 0.9850 - val_loss: 0.1439 - val_accuracy: 0.9623\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0339 - accuracy: 0.9966 - val_loss: 0.1460 - val_accuracy: 0.9623\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0449 - accuracy: 0.9932 - val_loss: 0.1502 - val_accuracy: 0.9623\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0415 - accuracy: 0.9914 - val_loss: 0.1513 - val_accuracy: 0.9623\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0380 - accuracy: 0.9870 - val_loss: 0.1638 - val_accuracy: 0.9623\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0622 - accuracy: 0.9824 - val_loss: 0.1422 - val_accuracy: 0.9623\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0420 - accuracy: 0.9922 - val_loss: 0.1561 - val_accuracy: 0.9623\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0392 - accuracy: 0.9927 - val_loss: 0.1646 - val_accuracy: 0.9623\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0639 - accuracy: 0.9741 - val_loss: 0.1659 - val_accuracy: 0.9623\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0254 - accuracy: 0.9979 - val_loss: 0.1537 - val_accuracy: 0.9623\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.1611 - val_accuracy: 0.9623\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0276 - accuracy: 0.9901 - val_loss: 0.1526 - val_accuracy: 0.9623\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9623\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0376 - accuracy: 0.9759 - val_loss: 0.1583 - val_accuracy: 0.9623\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0241 - accuracy: 0.9966 - val_loss: 0.1635 - val_accuracy: 0.9623\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.1822 - val_accuracy: 0.9623\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0267 - accuracy: 0.9979 - val_loss: 0.1519 - val_accuracy: 0.9623\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0173 - accuracy: 0.9979 - val_loss: 0.1523 - val_accuracy: 0.9623\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0273 - accuracy: 0.9966 - val_loss: 0.1473 - val_accuracy: 0.9811\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0254 - accuracy: 0.9966 - val_loss: 0.1539 - val_accuracy: 0.9811\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1612 - val_accuracy: 0.9623\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0153 - accuracy: 0.9979 - val_loss: 0.1574 - val_accuracy: 0.9811\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0177 - accuracy: 0.9966 - val_loss: 0.1655 - val_accuracy: 0.9811\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0228 - accuracy: 0.9949 - val_loss: 0.1665 - val_accuracy: 0.9811\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9623\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.1738 - val_accuracy: 0.9623\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9623\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0195 - accuracy: 0.9922 - val_loss: 0.1803 - val_accuracy: 0.9623\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0230 - accuracy: 0.9979 - val_loss: 0.1744 - val_accuracy: 0.9811\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0176 - accuracy: 0.9922 - val_loss: 0.1868 - val_accuracy: 0.9623\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.1999 - val_accuracy: 0.9623\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0148 - accuracy: 0.9966 - val_loss: 0.1855 - val_accuracy: 0.9811\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0145 - accuracy: 0.9979 - val_loss: 0.1805 - val_accuracy: 0.9623\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9623\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9623\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0162 - accuracy: 0.9979 - val_loss: 0.1827 - val_accuracy: 0.9811\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1873 - val_accuracy: 0.9623\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1891 - val_accuracy: 0.9623\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.2018 - val_accuracy: 0.9623\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2084 - val_accuracy: 0.9623\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2088 - val_accuracy: 0.9623\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0385 - accuracy: 0.9870 - val_loss: 0.2129 - val_accuracy: 0.9623\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.2133 - val_accuracy: 0.9623\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2217 - val_accuracy: 0.9623\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0184 - accuracy: 0.9870 - val_loss: 0.2280 - val_accuracy: 0.9623\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9623\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9623\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2280 - val_accuracy: 0.9623\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9811\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2186 - val_accuracy: 0.9811\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDdZiMJzYt99",
        "outputId": "e8a3612e-5d4f-4ee6-d574-56447f53c8ed"
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Y5JnVycXYt99",
        "outputId": "d76a210b-f942-4973-9ad7-42dfea0ee94b"
      },
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(100)\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ZkJhG4X_Yt9-",
        "outputId": "152111db-993a-481e-fa19-d6964165c426"
      },
      "source": [
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyeCpD18Yt9_"
      },
      "source": [
        "- Evaluation Step\n",
        "- Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJGzrAhZYt9_",
        "outputId": "9822e6be-fa87-4544-ba7e-9c668d482bff"
      },
      "source": [
        "score = model.evaluate(test_data, test_label)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3818 - accuracy: 0.9357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGy8kcCMYt-A",
        "outputId": "561c5b32-b49f-4415-eef5-25ec92faeed0"
      },
      "source": [
        "score"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38182321190834045, 0.9357143044471741]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALPieOiJYt-A"
      },
      "source": [
        "- If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
        "- Prediction should be > **92%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpw-jwdqYt-A"
      },
      "source": [
        "predictions=model.predict(test_data)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlN82WQSYt-B"
      },
      "source": [
        "y_pred = (predictions > 0.5)\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_UJsxh5Yt-B",
        "outputId": "f69b9d8f-52f0-431a-8ddd-7c019365d678"
      },
      "source": [
        "tf.math.confusion_matrix(\n",
        "    test_label, y_pred, num_classes=2, weights=None, dtype=tf.dtypes.int32,\n",
        "    name=None\n",
        ")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[47,  8],\n",
              "       [ 1, 84]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCD84zBaYt-C",
        "outputId": "c1799572-c18c-470b-d3b0-b7c1a74fb86e"
      },
      "source": [
        "np.count_nonzero(y_pred)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    }
  ]
}